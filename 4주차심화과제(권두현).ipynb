{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonDuHyeon/hanghae99/blob/main/4%EC%A3%BC%EC%B0%A8%EC%8B%AC%ED%99%94%EA%B3%BC%EC%A0%9C(%EA%B6%8C%EB%91%90%ED%98%84).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4주차 심화과제 수능문제"
      ],
      "metadata": {
        "id": "owTOpkIFX3wb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeHRwq3aR-bc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install transformers datasets evaluate accelerate scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import 부분"
      ],
      "metadata": {
        "id": "xtIeaAQ4_VsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "QObF2OAzYwLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b84520-20ad-4f49-d9bb-3e6db9b80910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
            "    handle._run()\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipykernel_491511/1942923946.py\", line 2, in <module>\n",
            "    import evaluate\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
            "    from .evaluation_suite import EvaluationSuite\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
            "    from ..evaluator import evaluator\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
            "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 26, in <module>\n",
            "    from ..image_processing_utils import BaseImageProcessor\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/transformers/image_processing_utils.py\", line 21, in <module>\n",
            "    from .image_transforms import center_crop, normalize, rescale\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/transformers/image_transforms.py\", line 22, in <module>\n",
            "    from .image_utils import (\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/transformers/image_utils.py\", line 59, in <module>\n",
            "    from torchvision.transforms import InterpolationMode\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/torchvision/__init__.py\", line 5, in <module>\n",
            "    from torchvision import datasets, io, models, ops, transforms, utils\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/torchvision/models/__init__.py\", line 17, in <module>\n",
            "    from . import detection, optical_flow, quantization, segmentation, video\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
            "    from .faster_rcnn import *\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/torchvision/models/detection/faster_rcnn.py\", line 16, in <module>\n",
            "    from .anchor_utils import AnchorGenerator\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/torchvision/models/detection/anchor_utils.py\", line 10, in <module>\n",
            "    class AnchorGenerator(nn.Module):\n",
            "  File \"/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/torchvision/models/detection/anchor_utils.py\", line 63, in AnchorGenerator\n",
            "    device: torch.device = torch.device(\"cpu\"),\n",
            "/home/harry/anaconda3/envs/hanghae/lib/python3.9/site-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/torch/csrc/utils/tensor_numpy.cpp:77.)\n",
            "  device: torch.device = torch.device(\"cpu\"),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MY CODE] 수능국어 데이터 load\n"
      ],
      "metadata": {
        "id": "FxyXrGlq_t0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Korean_data_path = \"/mnt/d/2023_11_KICE.json\"\n",
        "with open(Korean_data_path, 'r', encoding='utf-8') as file:\n",
        "    Korean_data = json.load(file)"
      ],
      "metadata": {
        "id": "HzxfcmYPZA7x",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MY CODE] 수능 국어 데이터 확인"
      ],
      "metadata": {
        "id": "O20QsB6-ikZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# type 확인\n",
        "print(type(Korean_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mQT4IHxkwEh",
        "outputId": "69eb5967-5c71-4f77-8bb8-f822d48c8b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_Korean = Korean_data[0]\n",
        "print(json.dumps(sample_Korean, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpVt9V-TpssG",
        "outputId": "73e0462f-2695-4846-ed8b-b45f4ff3dff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"2023_11_KICE_1-3\",\n",
            "  \"paragraph\": \"사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 가지가 있겠지만 그 중심에는 ‘소통의 즐거움’이 있다.독자는 독서를 통해 책과 소통하는 즐거움을 경험한다. 독서는필자와 간접적으로 대화하는 소통 행위이다. 독자는 자신이 속한사회나 시대의 영향 아래 필자가 속해 있거나 드러내고자 하는 사회나 시대를 경험한다. 직접 경험하지 못했던 다양한 삶을 필자를 매개로 만나고 이해하면서 독자는 더 넓은 시야로 세계를바라볼 수 있다. 이때 같은 책을 읽은 독자라도 독자의 배경지식이나 관점 등의 독자 요인, 읽기 환경이나 과제 등의 상황 요인이 다르므로, 필자가 보여 주는 세계를 그대로 수용하지 않고 저마다 소통 과정에서 다른 의미를 구성할 수 있다.[A] (이러한 소통은 독자가 책의 내용에 대해 질문하고 답을 찾아내는 과정에서 가능해진다. 독자는 책에서 답을 찾는 질문, 독자 자신에게서 답을 찾는 질문 등을 제기할 수 있다. 전자의 경우 책에 명시된 내용에서 답을 발견할 수 있고, 책의 내용들을 관계 지으며 답에 해당하는 내용을 스스로 구성할 수도 있다. 또한 후자의 경우 책에는 없는 독자의 경험에서 답을 찾을 수 있다. 이런 질문들을 풍부히 생성하고 주체적으로 답을 찾을 때 소통의 즐거움은 더 커진다.)한편 독자는 ㉠ (다른 독자와 소통하는 즐거움을 경험할 수도 있다.) 책과의 소통을 통해 개인적으로 형성한 의미를 독서 모임이나 독서 동아리 등에서 다른 독자들과 나누는 일이 이에 해당한다. 비슷한 해석에 서로 공감하며 기존 인식을 강화하거나 관점의 차이를 확인하고 기존 인식을 조정하는 과정에서, 독자는자신의 인식을 심화 확장할 수 있다. 최근 소통 공간이 온라인으로 확대되면서 독서를 통해 다른 독자들과 소통하며 즐거움을누리는 양상이 더 다양해지고 있다. 자신의 독서 경험을 담은 글이나 동영상을 생산 공유함으로써, 책을 읽지 않은 타인이 책과 소통하도록 돕는 것도 책을 통한 소통의 즐거움을 나누는 일이다.\",\n",
            "  \"type\": 0,\n",
            "  \"problems\": [\n",
            "    {\n",
            "      \"question\": \"윗글의 내용과 일치하지 않는 것은?\",\n",
            "      \"choices\": [\n",
            "        \"같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.\",\n",
            "        \"다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다\",\n",
            "        \"독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.\",\n",
            "        \"독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.\",\n",
            "        \"독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다\"\n",
            "      ],\n",
            "      \"answer\": 4,\n",
            "      \"score\": 2\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?\",\n",
            "      \"question_plus\": \"ⓐ('음악 시간에 들었던 베토벤의 교향곡 <합창>이 위대한 작품인 이유는 무엇일까?'하는 생각)에, 베토벤에 대한 책을 빌렸다. 책에서는 기약만으로 구성됐던 교향곡에 성악을 결합헤 개성을 드러냈다는 점에서 ⓑ(이 곡이 낭만주의 음악의 특징을 보여 준다고 했다.) <합창>을 해설한 부분에 이어, 베토벤의 생애에 관한 뒷부분도 읽었는데, ⓒ(이 내용들을 종합해, 절망적 상황에서도 열정적으로 자신이 좋아하는 일을 했기에 교향곡 구성의 새로움을 보여 준 명작이 탄생했음을 알게 됐다.) 이후 ⓓ(내가 진정으로 좋아하는 일이 무엇인지 나에게 묻게 되었다.) ⓔ(글 쓰는 일에서 가장 큰 행복을 느꼈던 나를 발견)할 수 있었고, 나도 어떤 상황에서든 좋아하는 일을 계속해야겠다고 생각했다.\",\n",
            "      \"choices\": [\n",
            "        \"ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.\",\n",
            "        \"ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.\",\n",
            "        \"ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.\",\n",
            "        \"ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.\",\n",
            "        \"ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.\"\n",
            "      ],\n",
            "      \"answer\": 5,\n",
            "      \"score\": 3\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?\",\n",
            "      \"choices\": [\n",
            "        \"스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.\",\n",
            "        \"독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.\",\n",
            "        \"개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.\",\n",
            "        \"자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.\",\n",
            "        \"오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.\"\n",
            "      ],\n",
            "      \"answer\": 1,\n",
            "      \"score\": 2\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MY CODE] GPT API 호출"
      ],
      "metadata": {
        "id": "oR-w9k-ulkjd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9UJ0eTwRtfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l /mnt/d/hanghae99/apikey/.env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVay8owfR9eC",
        "outputId": "01864fa3-5c7c-406b-e493-6cd0fb311e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxrwxrwx 1 harry harry 180 Jan  9 13:20 \u001b[0m\u001b[01;32m/mnt/d/hanghae99/apikey/.env\u001b[0m*\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import openai\n",
        "load_dotenv('/mnt/d/hanghae99/apikey/.env')  # .env 파일을 로드\n",
        "\n",
        "\n",
        "\n",
        "# 환경 변수 확인\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "openai.Model.list()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p3RhVqBlnjf",
        "outputId": "507de04b-94d8-4442-cf7b-63c4a819d487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7fde93999770> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview-2024-10-01\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727389042,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-audio-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734387424,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727659998,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview-2024-10-01\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727131766,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-audio-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734115920,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-realtime-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734387380,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-2\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698798177,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-1106-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698957206,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1733945430,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677610602,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-0125\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706048358,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692901427,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634615,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"whisper-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677532384,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-3\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698785189,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-16k\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1683758102,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"omni-moderation-latest\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1731689265,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-preview-2024-09-12\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648865,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"omni-moderation-2024-09-26\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1732734466,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053533,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648897,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1687882411,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-0613\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1686588896,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"chatgpt-4o-latest\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1723515131,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-0125-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706037612,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699046015,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634301,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-ada-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1671217299,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698959748,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727460443,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo-2024-04-09\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1712601677,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1712361441,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1681940951,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053241,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1694122472,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706037777,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-realtime-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734112601,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1715367049,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-08-06\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1722814719,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-05-13\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1715368132,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-3-small\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1705948997,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-2024-07-18\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1721172717,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-11-20\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1731975040,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1721172741,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-3-large\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1705953180,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725649008,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-mini-2024-09-12\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648979,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734034239,\n",
              "      \"owned_by\": \"system\"\n",
              "    }\n",
              "  ]\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LGDZ5IfU6zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def safe_api_call(prompt, max_tokens=5, retries=3, model=\"gpt-4o\", delay=10):\n",
        "    \"\"\"\n",
        "    OpenAI API 호출을 안전하게 처리하는 함수.\n",
        "    RateLimitError 및 기타 오류 발생 시 재시도 로직 포함.\n",
        "    \"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"당신은 수능 국어 문제를 푸는 전문 AI입니다.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=max_tokens,\n",
        "\n",
        "\n",
        "            )\n",
        "            return response  # 성공적으로 응답 반환\n",
        "        except openai.error.RateLimitError as e:\n",
        "            print(f\"Rate limit exceeded. Retrying in {delay} seconds... (Attempt {attempt + 1}/{retries})\")\n",
        "            time.sleep(delay)  # 대기 후 재시도\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error: {e}. Retrying... (Attempt {attempt + 1}/{retries})\")\n",
        "            time.sleep(delay)  # 대기 후 재시도\n",
        "\n",
        "    # 최대 재시도 횟수 초과 시 예외 발생\n",
        "    raise Exception(\"Failed to get a response from OpenAI API after multiple retries.\")\n"
      ],
      "metadata": {
        "id": "w8HHQh2pfrRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MY CODE] 결과 비교 함수 정의"
      ],
      "metadata": {
        "id": "Aw7EH0IZtUDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 점수 계산 함수\n",
        "def calculate_score(predictions, problems):\n",
        "    total_score = 0\n",
        "    results = []  # 문제별 결과 저장\n",
        "    for idx, (pred, problem) in enumerate(zip(predictions, problems)):\n",
        "        correct_answer = problem[\"answer\"]\n",
        "        is_correct = pred == correct_answer\n",
        "        total_score += problem[\"score\"] if is_correct else 0\n",
        "\n",
        "        # 문제별 결과 저장\n",
        "        results.append({\n",
        "            \"문제 번호\": idx + 1,\n",
        "            \"GPT-4 예측\": pred,\n",
        "            \"정답\": correct_answer,\n",
        "            \"예측 결과\": \"정답\" if is_correct else \"오답\",\n",
        "            \"배점\": problem[\"score\"] if is_correct else 0\n",
        "        })\n",
        "    return total_score, results\n"
      ],
      "metadata": {
        "id": "ZP31fRa9td3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MY CODE] prediction 함수 정의"
      ],
      "metadata": {
        "id": "7zOqxegft6DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "    # 4. prediction 함수 정의\n",
        "def prediction(problem):\n",
        "    \"\"\"\n",
        "    Safe API Call을 사용하여 문제에 대한 예측 결과 반환.\n",
        "    \"\"\"\n",
        "    plus =  problem.get('question_plus','')\n",
        "\n",
        "    prompt = f\"\"\"다음은 수능 국어 문제입니다. 가장 적절한 답을 선택하세요.\n",
        "     본문:\n",
        "    {problem['paragraph']}\n",
        "\n",
        "    질문:\n",
        "    {problem['question']}\n",
        "    {plus}\n",
        "    선택지:\n",
        "    {', '.join(f'({i + 1}) {choice}' for i, choice in enumerate(problem['choices']))}\n",
        "\n",
        "    \"1, 2, 3, 4, 5 중 하나의 숫자로만 답하세요. 다른 정보는 포함하지 마세요.\"\n",
        "    \"\"\"\n",
        "\n",
        "    # Safe API 호출로 응답 받기\n",
        "    response = safe_api_call(prompt, max_tokens=5, retries=5, model=\"gpt-4o\", delay=10)\n",
        "\n",
        "\n",
        "    # GPT-4의 응답에서 정답 추출\n",
        "    gpt_answer = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "\n",
        "    # 정규 표현식으로 숫자 추출 (1-5에 해당하는 숫자만)\n",
        "    match = re.search(r'\\b[1-5]\\b', gpt_answer)\n",
        "    if match:\n",
        "        return int(match.group())  # 숫자를 반환\n",
        "    else:\n",
        "        # 오류 발생 시 1번으로 가정 (예외 처리)\n",
        "        return 1"
      ],
      "metadata": {
        "id": "rkBHqwMkgqVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MY CODE] 실행"
      ],
      "metadata": {
        "id": "MYQ1QyxWfrvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 문제 데이터 처리\n",
        "problems = []\n",
        "for section in Korean_data:\n",
        "    for problem in section[\"problems\"]:\n",
        "        # 각 문제에 상위 paragraph 추가\n",
        "        problem[\"paragraph\"] = section[\"paragraph\"]\n",
        "        problems.append(problem)\n",
        "\n",
        "# 모든 문제에 대해 GPT-4 예측 실행 (순차적으로 처리)\n",
        "predictions = []\n",
        "for idx, problem in enumerate(problems):\n",
        "    try:\n",
        "        print(f\"Processing problem {idx + 1}/{len(problems)}...\")\n",
        "        pred = prediction(problem)  # 문제 예측\n",
        "        predictions.append(pred)\n",
        "        time.sleep(2)  # 요청 간 1초 대기\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing problem {idx + 1}: {e}\")\n",
        "        predictions.append(1)  # 실패 시 기본값\n",
        "\n",
        "# 점수 계산 및 결과 출력\n",
        "final_score, results = calculate_score(predictions, problems)\n",
        "\n",
        "# 문제별 결과 출력\n",
        "print(\"\\n문제별 예측 결과:\")\n",
        "for result in results:\n",
        "    print(f\"문제 {result['문제 번호']}: GPT-4 예측 = {result['GPT-4 예측']}, \"\n",
        "          f\"정답 = {result['정답']}, 결과 = {result['예측 결과']}, 배점 = {result['배점']}\")\n",
        "\n",
        "# 최종 점수 출력\n",
        "print(f\"\\nGPT-4 최종 점수: {final_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4TYBQq7g7Yi",
        "outputId": "045e4aa9-57c2-4f13-c985-ba20a0be5a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing problem 1/45...\n",
            "Processing problem 2/45...\n",
            "Processing problem 3/45...\n",
            "Processing problem 4/45...\n",
            "Processing problem 5/45...\n",
            "Processing problem 6/45...\n",
            "Processing problem 7/45...\n",
            "Processing problem 8/45...\n",
            "Processing problem 9/45...\n",
            "Processing problem 10/45...\n",
            "Processing problem 11/45...\n",
            "Processing problem 12/45...\n",
            "Processing problem 13/45...\n",
            "Processing problem 14/45...\n",
            "Processing problem 15/45...\n",
            "Processing problem 16/45...\n",
            "Processing problem 17/45...\n",
            "Processing problem 18/45...\n",
            "Processing problem 19/45...\n",
            "Processing problem 20/45...\n",
            "Processing problem 21/45...\n",
            "Processing problem 22/45...\n",
            "Processing problem 23/45...\n",
            "Processing problem 24/45...\n",
            "Processing problem 25/45...\n",
            "Processing problem 26/45...\n",
            "Processing problem 27/45...\n",
            "Processing problem 28/45...\n",
            "Processing problem 29/45...\n",
            "Processing problem 30/45...\n",
            "Processing problem 31/45...\n",
            "Processing problem 32/45...\n",
            "Processing problem 33/45...\n",
            "Processing problem 34/45...\n",
            "Processing problem 35/45...\n",
            "Processing problem 36/45...\n",
            "Processing problem 37/45...\n",
            "Processing problem 38/45...\n",
            "Processing problem 39/45...\n",
            "Processing problem 40/45...\n",
            "Processing problem 41/45...\n",
            "Processing problem 42/45...\n",
            "Processing problem 43/45...\n",
            "Processing problem 44/45...\n",
            "Processing problem 45/45...\n",
            "\n",
            "문제별 예측 결과:\n",
            "문제 1: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 2: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 3\n",
            "문제 3: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 4: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 5: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 6: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 7: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 8: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 3\n",
            "문제 9: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 10: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 11: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 12: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 3\n",
            "문제 13: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 14: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 15: GPT-4 예측 = 3, 정답 = 4, 결과 = 오답, 배점 = 0\n",
            "문제 16: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 17: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 3\n",
            "문제 18: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 19: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 20: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 21: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 3\n",
            "문제 22: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 23: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 24: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 3\n",
            "문제 25: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 26: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 27: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 28: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 29: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 30: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 3\n",
            "문제 31: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 32: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 33: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 34: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 3\n",
            "문제 35: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 36: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 37: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 38: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 39: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 40: GPT-4 예측 = 5, 정답 = 3, 결과 = 오답, 배점 = 0\n",
            "문제 41: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 3\n",
            "문제 42: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 43: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 44: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 45: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 3\n",
            "\n",
            "GPT-4 최종 점수: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [LOG] question plus 추가후 점수 96점"
      ],
      "metadata": {
        "id": "mfd-zWfMfw-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MY CODE] 프롬프트2 구체적인 지시를 추가"
      ],
      "metadata": {
        "id": "8jU9OpDElHrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from nltk.tokenize import sent_tokenize\n",
        "def safe_api_call(prompt, max_tokens=5, retries=3, model=\"gpt-4o\", delay=60):\n",
        "    \"\"\"\n",
        "    OpenAI API 호출을 안전하게 처리하는 함수.\n",
        "    RateLimitError 및 기타 오류 발생 시 재시도 로직 포함.\n",
        "    \"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"당신은 수능 국어 문제를 푸는 전문 AI입니다.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=0.2  # 약간의 변동성 허\n",
        "            )\n",
        "            return response  # 성공적으로 응답 반환\n",
        "        except openai.error.RateLimitError as e:\n",
        "            print(f\"Rate limit exceeded. Retrying in {delay} seconds... (Attempt {attempt + 1}/{retries})\")\n",
        "            time.sleep(delay)  # 대기 후 재시도\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error: {e}. Retrying... (Attempt {attempt + 1}/{retries})\")\n",
        "            time.sleep(delay)  # 대기 후 재시도\n",
        "\n",
        "    # 최대 재시도 횟수 초과 시 예외 발생\n",
        "    raise Exception(\"Failed to get a response from OpenAI API after multiple retries.\")\n",
        "\n",
        "\n",
        "# 4. prediction 함수 정의\n",
        "def prediction(problem):\n",
        "    plus =  problem.get('question_plus','')\n",
        "     # 지문 요약\n",
        "    prompt = f\"\"\"다음은 대한민국 수능 국어 문제입니다. 본문과 문제를 분석하여 가장 적절한 답을 선택하세요.\n",
        "\n",
        "    ### 본문 ###\n",
        "    {problem['paragraph']}\n",
        "\n",
        "    ### 질문 ###\n",
        "    {problem['question']}\n",
        "    {plus}\n",
        "    ### 선택지 ###\n",
        "    {', '.join(f'({i + 1}) {choice}' for i, choice in enumerate(problem['choices']))}\n",
        "\n",
        "\n",
        "     ### 작업 지침 ###\n",
        "    1. 본문과 질문을 논리적으로 분석합니다.\n",
        "    2. 각 선택지와 본문을 비교하여, 가장 근거가 명확한 선택지를 고르세요.\n",
        "    3. 불확실한 경우, 본문에서 가장 관련성이 높은 단서를 포함한 선택지를 선택하세요.\n",
        "\n",
        "\n",
        "    ### 답변 형식 ###\n",
        "    - 정답은 반드시 숫자로만 작성하세요. 예: 1, 2, 3, 4, 5\n",
        "    - 다른 정보는 포함하지 마세요.\n",
        "    \"\"\"\n",
        "\n",
        "    # Safe API 호출로 응답 받기\n",
        "    response = safe_api_call(prompt, max_tokens=5, retries=5, model=\"gpt-4o\", delay=10)\n",
        "\n",
        "    # GPT-4의 응답에서 정답 추출\n",
        "    gpt_answer = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "     # 숫자가 아닌 경우 또는 범위를 벗어난 경우 예외 발생\n",
        "    if not gpt_answer.isdigit() or int(gpt_answer) not in range(1, 6):\n",
        "        raise ValueError(f\"Unexpected response: {gpt_answer}\")\n",
        "\n",
        "    # 정답 반환\n",
        "    return int(gpt_answer)\n",
        "\n",
        "\n",
        "# 문제 데이터 처리\n",
        "problems = []\n",
        "for section in Korean_data:\n",
        "    for problem in section[\"problems\"]:\n",
        "        # 각 문제에 상위 paragraph 추가\n",
        "        problem[\"paragraph\"] = section[\"paragraph\"]\n",
        "        problems.append(problem)\n",
        "\n",
        "# 모든 문제에 대해 GPT-4 예측 실행 (순차적으로 처리)\n",
        "predictions = []\n",
        "for idx, problem in enumerate(problems):\n",
        "    try:\n",
        "        print(f\"Processing problem {idx + 1}/{len(problems)}...\")\n",
        "        pred = prediction(problem)  # 문제 예측\n",
        "        predictions.append(pred)\n",
        "        time.sleep(2)  # 요청 간 2초 대기\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing problem {idx + 1}: {e}\")\n",
        "        predictions.append(1)  # 실패 시 기본값\n",
        "\n",
        "# 점수 계산 및 결과 출력\n",
        "final_score, results = calculate_score(predictions, problems)\n",
        "\n",
        "# 문제별 결과 출력\n",
        "print(\"\\n문제별 예측 결과:\")\n",
        "for result in results:\n",
        "    print(f\"문제 {result['문제 번호']}: GPT-4 예측 = {result['GPT-4 예측']}, \"\n",
        "          f\"정답 = {result['정답']}, 결과 = {result['예측 결과']}, 배점 = {result['배점']}\")\n",
        "\n",
        "# 최종 점수 출력\n",
        "print(f\"\\nGPT-4 최종 점수: {final_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LovgMYrTvho1",
        "outputId": "62794da6-a6d6-4b85-b987-97eba08cec7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing problem 1/45...\n",
            "Processing problem 2/45...\n",
            "Processing problem 3/45...\n",
            "Processing problem 4/45...\n",
            "Processing problem 5/45...\n",
            "Processing problem 6/45...\n",
            "Processing problem 7/45...\n",
            "Processing problem 8/45...\n",
            "Processing problem 9/45...\n",
            "Processing problem 10/45...\n",
            "Processing problem 11/45...\n",
            "Processing problem 12/45...\n",
            "Processing problem 13/45...\n",
            "Processing problem 14/45...\n",
            "Processing problem 15/45...\n",
            "Processing problem 16/45...\n",
            "Processing problem 17/45...\n",
            "Processing problem 18/45...\n",
            "Processing problem 19/45...\n",
            "Processing problem 20/45...\n",
            "Processing problem 21/45...\n",
            "Processing problem 22/45...\n",
            "Processing problem 23/45...\n",
            "Processing problem 24/45...\n",
            "Processing problem 25/45...\n",
            "Processing problem 26/45...\n",
            "Processing problem 27/45...\n",
            "Processing problem 28/45...\n",
            "Processing problem 29/45...\n",
            "Processing problem 30/45...\n",
            "Processing problem 31/45...\n",
            "Processing problem 32/45...\n",
            "Processing problem 33/45...\n",
            "Processing problem 34/45...\n",
            "Processing problem 35/45...\n",
            "Processing problem 36/45...\n",
            "Processing problem 37/45...\n",
            "Processing problem 38/45...\n",
            "Processing problem 39/45...\n",
            "Processing problem 40/45...\n",
            "Processing problem 41/45...\n",
            "Processing problem 42/45...\n",
            "Processing problem 43/45...\n",
            "Processing problem 44/45...\n",
            "Processing problem 45/45...\n",
            "\n",
            "문제별 예측 결과:\n",
            "문제 1: GPT-4 예측 = 5, 정답 = 4, 결과 = 오답, 배점 = 0\n",
            "문제 2: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 3\n",
            "문제 3: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 4: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 5: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 6: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 7: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 8: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 3\n",
            "문제 9: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 10: GPT-4 예측 = 1, 정답 = 4, 결과 = 오답, 배점 = 0\n",
            "문제 11: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 12: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 3\n",
            "문제 13: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 14: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 15: GPT-4 예측 = 3, 정답 = 4, 결과 = 오답, 배점 = 0\n",
            "문제 16: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 17: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 3\n",
            "문제 18: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 19: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 20: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 21: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 3\n",
            "문제 22: GPT-4 예측 = 3, 정답 = 1, 결과 = 오답, 배점 = 0\n",
            "문제 23: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 24: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 3\n",
            "문제 25: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 26: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 27: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 28: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 29: GPT-4 예측 = 3, 정답 = 1, 결과 = 오답, 배점 = 0\n",
            "문제 30: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 3\n",
            "문제 31: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 32: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 33: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 34: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 3\n",
            "문제 35: GPT-4 예측 = 1, 정답 = 1, 결과 = 정답, 배점 = 2\n",
            "문제 36: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 37: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 38: GPT-4 예측 = 4, 정답 = 4, 결과 = 정답, 배점 = 2\n",
            "문제 39: GPT-4 예측 = 5, 정답 = 4, 결과 = 오답, 배점 = 0\n",
            "문제 40: GPT-4 예측 = 3, 정답 = 3, 결과 = 정답, 배점 = 2\n",
            "문제 41: GPT-4 예측 = 5, 정답 = 2, 결과 = 오답, 배점 = 0\n",
            "문제 42: GPT-4 예측 = 3, 정답 = 4, 결과 = 오답, 배점 = 0\n",
            "문제 43: GPT-4 예측 = 5, 정답 = 5, 결과 = 정답, 배점 = 2\n",
            "문제 44: GPT-4 예측 = 2, 정답 = 2, 결과 = 정답, 배점 = 2\n",
            "문제 45: GPT-4 예측 = 2, 정답 = 1, 결과 = 오답, 배점 = 0\n",
            "\n",
            "GPT-4 최종 점수: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [LOG] 오히려 성능이 더 떨어졌다 작업 지침 내용수정 후 다시 시도해볼만하다.\n",
        "추후 개인적으로 해서 성능 개선 연습을 진행하겠습니다."
      ],
      "metadata": {
        "id": "bbOOqEXihB5c"
      }
    }
  ]
}